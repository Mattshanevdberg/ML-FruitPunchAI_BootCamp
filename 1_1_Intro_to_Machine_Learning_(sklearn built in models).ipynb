{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mattshanevdberg/ML-FruitPunchAI_BootCamp/blob/main/1_1_Intro_to_Machine_Learning_(sklearn%20built%20in%20models).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0Y-HINws7t4z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Common AI models\n",
        "\n",
        "In this first notebook you will practice AI with some common Machine Learning models. You're expected to already have some basic experience in playing around with Python. If you find yourself stranded on one of the assignments please put a question in the bootcamp-questions Slack channel. There are mentors there that are eager to help."
      ],
      "metadata": {
        "id": "9JixMZox71uW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classic machine learning models\n",
        "\n",
        "## Assignment 1\n",
        "From the Sklearn library choose models of at least the following types, train them on the 6 imported datasets, evaluate their accuracy or R^2 and see which model works best on which dataset. (Note that there are both regression and classification sets)\n",
        "* Tree\n",
        "* Neural Network\n",
        "* Neighbors\n",
        "* Ensemble\n",
        "* Naive Byes (classification only)\n",
        "* Linear\n"
      ],
      "metadata": {
        "id": "BQjIosCd73lX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris, load_boston, load_diabetes, load_digits, load_wine, load_breast_cancer\n",
        "from sklearn.metrics import accuracy_score, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# importintg other models\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "#from sklearn.tree import ExtraTreeClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "#from sklearn.svm.classes import OneClassSVM\n",
        "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
        "#from sklearn.neighbors.classification import RadiusNeighborsClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "#from sklearn.multioutput import ClassifierChain\n",
        "#from sklearn.multioutput import MultiOutputClassifier\n",
        "#from sklearn.multiclass import OutputCodeClassifier\n",
        "#from sklearn.multiclass import OneVsOneClassifier\n",
        "#from sklearn.multiclass import OneVsRestClassifier\n",
        "#from sklearn.linear_model.stochastic_gradient import SGDClassifier\n",
        "#from sklearn.linear_model.ridge import RidgeClassifierCV\n",
        "#from sklearn.linear_model.ridge import RidgeClassifier\n",
        "#from sklearn.linear_model.passive_aggressive import PassiveAggressiveClassifier    \n",
        "#from sklearn.gaussian_process.gpc import GaussianProcessClassifier\n",
        "#from sklearn.ensemble.voting_classifier import VotingClassifier\n",
        "#from sklearn.ensemble.weight_boosting import AdaBoostClassifier\n",
        "#from sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\n",
        "#from sklearn.ensemble.bagging import BaggingClassifier\n",
        "#from sklearn.ensemble.forest import ExtraTreesClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "#from sklearn.naive_bayes import BernoulliNB\n",
        "#from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "#from sklearn.semi_supervised import LabelPropagation\n",
        "#from sklearn.semi_supervised import LabelSpreading\n",
        "#from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.svm import LinearSVC, LinearSVR\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "#from sklearn.linear_model import LogisticRegressionCV\n",
        "#from sklearn.naive_bayes import MultinomialNB  \n",
        "#from sklearn.neighbors import NearestCentroid\n",
        "#from sklearn.svm import NuSVC\n",
        "from xgboost import XGBRegressor, XGBClassifier\n",
        "\n",
        "# creating list of datasets\n",
        "dataset_list = [load_iris(), load_boston(), load_diabetes(), load_digits(), load_wine(), load_breast_cancer()] \n",
        "dataset_name_list = [load_iris.__name__, load_boston.__name__, load_diabetes.__name__, load_digits.__name__, load_wine.__name__, load_breast_cancer.__name__] \n",
        "\n",
        "# creating list of models for classification\n",
        "model_list_class = [DecisionTreeClassifier(), MLPClassifier(), XGBClassifier(), KNeighborsClassifier(), RandomForestClassifier(), LinearSVC(), LogisticRegression()]\n",
        "model_name_list_class = [DecisionTreeClassifier.__name__, MLPClassifier.__name__, XGBClassifier.__name__, KNeighborsClassifier.__name__, RandomForestClassifier.__name__, LinearSVC.__name__, LogisticRegression.__name__, GaussianNB.__name__]\n",
        "\n",
        "# creating list of models for regression\n",
        "model_list_reg = [DecisionTreeRegressor(), MLPRegressor(), XGBRegressor(), KNeighborsRegressor(), RandomForestRegressor(), LinearSVR(), LinearRegression()]\n",
        "model_name_list_reg = [DecisionTreeRegressor.__name__, MLPRegressor.__name__, XGBRegressor.__name__, KNeighborsRegressor.__name__, RandomForestRegressor.__name__, LinearSVR.__name__, LinearRegression.__name__]\n",
        "\n",
        "# loading scaler for NN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# # Example of how to load a dataset\n",
        "print(load_diabetes().DESCR)\n",
        "\n",
        "# X = load_iris().data\n",
        "# y = load_iris().target\n",
        "\n",
        "# # Create a train/test split\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boxe8FST7zpC",
        "outputId": "a92015a0-7d58-4e33-f048-71202594e66b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _diabetes_dataset:\n",
            "\n",
            "Diabetes dataset\n",
            "----------------\n",
            "\n",
            "Ten baseline variables, age, sex, body mass index, average blood\n",
            "pressure, and six blood serum measurements were obtained for each of n =\n",
            "442 diabetes patients, as well as the response of interest, a\n",
            "quantitative measure of disease progression one year after baseline.\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "  :Number of Instances: 442\n",
            "\n",
            "  :Number of Attributes: First 10 columns are numeric predictive values\n",
            "\n",
            "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
            "\n",
            "  :Attribute Information:\n",
            "      - age     age in years\n",
            "      - sex\n",
            "      - bmi     body mass index\n",
            "      - bp      average blood pressure\n",
            "      - s1      tc, total serum cholesterol\n",
            "      - s2      ldl, low-density lipoproteins\n",
            "      - s3      hdl, high-density lipoproteins\n",
            "      - s4      tch, total cholesterol / HDL\n",
            "      - s5      ltg, possibly log of serum triglycerides level\n",
            "      - s6      glu, blood sugar level\n",
            "\n",
            "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
            "\n",
            "Source URL:\n",
            "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
            "\n",
            "For more information see:\n",
            "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
            "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of how to load/train a model and evaluate\n",
        "\n",
        "tree = DecisionTreeClassifier()             # Load\n",
        "fitted_tree = tree.fit(X_train, y_train)    # Train\n",
        "y_pred = fitted_tree.predict(X_test)        # Predict on unseen data\n",
        "# print(y_pred)\n",
        "# print(y_test)\n",
        "acc_score = accuracy_score(y_test, y_pred)  # Evaluate accuracy score\n",
        "r2_score2 = r2_score(y_test, y_pred)         # Evaluate R^2 score\n",
        "\n",
        "print(f'On the {load_iris.__name__} dataset the {DecisionTreeClassifier.__name__} reaches an accuracy score of {acc_score} and a R^2 score of {r2_score2}')\n",
        "\n",
        "# Running Neural Netwrok\n",
        "\n",
        "NN = MLPClassifier(hidden_layer_sizes=(50,))             # Load\n",
        "fitted_NN = NN.fit(X_train, y_train)    # Train\n",
        "y_pred = fitted_NN.predict(X_test)        # Predict on unseen data\n",
        "# print(y_pred)\n",
        "# print(y_test)\n",
        "acc_score = accuracy_score(y_test, y_pred)  # Evaluate accuracy score\n",
        "#print(\"predicted:\" + y_pred[:10] + \"actual:\" + y_test[:10])\n",
        "r2_score2 = r2_score(y_test, y_pred)         # Evaluate R^2 score\n",
        "\n",
        "print(f'On the {load_iris.__name__} dataset the {MLPClassifier.__name__} reaches an accuracy score of {acc_score} and a R^2 score of {r2_score2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfM5F3WL_GdP",
        "outputId": "19dd03d4-af74-4174-9164-fc16d345412b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On the load_iris dataset the DecisionTreeClassifier reaches an accuracy score of 0.98 and a R^2 score of 0.9712808730614589\n",
            "On the load_iris dataset the MLPClassifier reaches an accuracy score of 1.0 and a R^2 score of 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fundction for loading dataset\n",
        "def load_dataset(dataset):\n",
        "  X = dataset.data\n",
        "  y = dataset.target\n",
        "  return X, y\n",
        "\n",
        "# function for fitting models:\n",
        "def fit_and_test_model(model, X_train, y_train, X_test, y_test, dataset_name, model_name):\n",
        "  fitted_model = model.fit(X=X_train, y=y_train)    # Train\n",
        "  y_pred = fitted_model.predict(X_test)        # Predict on unseen data\n",
        "\n",
        "  if 'Classification' in dataset.DESCR:\n",
        "    score = accuracy_score(y_test, y_pred)  # Evaluate accuracy score\n",
        "  else:\n",
        "    score = r2_score(y_test, y_pred)         # Evaluate R^2 score\n",
        "\n",
        "  #print(f'On the {dataset_name} dataset the {model_name} reaches an score of {score}')\n",
        "  \n",
        "  return score\n",
        "\n",
        "def find_highest_score(score_dict):\n",
        "  \n",
        "  for dataset, model_list in score_dict.items():\n",
        "    best_score = -10\n",
        "    #print(dataset)\n",
        "    #print(model_list)\n",
        "    for model, score in model_list.items():\n",
        "      #print(model)\n",
        "      #print(score)\n",
        "      if score.get('score') > best_score:\n",
        "        best_score = score.get('score')\n",
        "        best_model = model\n",
        "    print(dataset, best_model, best_score)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kwttooEQz414"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "count = 0\n",
        "score_dict = {}\n",
        "for dataset in dataset_list:\n",
        "  X, y = load_dataset(dataset)\n",
        "  dataset_name = dataset_name_list[count]\n",
        "  score_dict[dataset_name] = {}\n",
        "  count += 1\n",
        "  mcount = 0\n",
        "  if 'Classification' in dataset.DESCR:\n",
        "    for model in model_list_class:\n",
        "      model_name = model_name_list_class[mcount]\n",
        "      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "      score = fit_and_test_model(model, X_train, y_train, X_test, y_test, dataset_name, model_name)\n",
        "\n",
        "      #score_dict[dataset_name][model_name] = {}\n",
        "      score_dict[dataset_name][model_name] = {'score': score}\n",
        "\n",
        "      mcount +=1\n",
        "  else:\n",
        "    for model in model_list_reg:\n",
        "      model_name = model_name_list_reg[mcount]\n",
        "      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "      score = fit_and_test_model(model, X_train, y_train, X_test, y_test, dataset_name, model_name)\n",
        "\n",
        "      score_dict[dataset_name][model_name] = {'score': score}\n",
        "\n",
        "      mcount +=1\n",
        "\n",
        "find_highest_score(score_dict)\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1418a215-cf50-43ac-c4d6-bdd5b83b50fa",
        "id": "lcwLlHxGz8jt"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11:17:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11:17:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11:17:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "load_iris MLPClassifier 1.0\n",
            "load_boston XGBRegressor 0.8771694297428649\n",
            "load_diabetes LinearRegression 0.510395426135144\n",
            "load_digits KNeighborsClassifier 0.9932659932659933\n",
            "load_wine RandomForestClassifier 1.0\n",
            "load_breast_cancer KNeighborsRegressor 0.8497298630812877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment 2\n",
        "Use XGBoost running on GPU to predict the same datasets. You can activate GPU acceleration in the Runtime tab:\n",
        "Runtime -> Change runtime type -> Select GPU from the dropdown"
      ],
      "metadata": {
        "id": "2lkpnT2YJIgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "21RqHj3JJJRk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}